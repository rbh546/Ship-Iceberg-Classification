{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ship-iceberg clsiification from satellite radar images\n",
    "\n",
    "A simple convolutional neural network is used to classify ship/iceberg from radar satellite images. The network is found to produce an accuracy of 87%. The model was developed using the previous version of tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from scipy import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from cnn_utils import *\n",
    "from tqdm import tqdm \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data was converted to NumPy array first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train_data.npy')\n",
    "test_data=np.load('test_data.npy')\n",
    "num=155\n",
    "print(train_data.shape) #check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the images are greyscale; however,each image has values from 2 channels (band_1 and band_2). Some images contain the incident angle of the satellite, which is passed as a separate parameter forthe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE=75\n",
    "X_train_orig=np.empty([len(train_data),IMG_SIZE,IMG_SIZE,2])\n",
    "X_train_orig_lin=np.empty([len(train_data),IMG_SIZE,IMG_SIZE,2])\n",
    "Y_train_orig=np.empty([len(train_data),1])\n",
    "X_test_orig=np.empty([len(test_data),IMG_SIZE,IMG_SIZE,2])\n",
    "\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    X_train_orig[i,:,:,0]=np.asarray(train_data[i]['band_1']).reshape(IMG_SIZE,IMG_SIZE)\n",
    "    X_train_orig[i,:,:,1]=np.asarray(train_data[i]['band_2']).reshape(IMG_SIZE,IMG_SIZE)\n",
    "    Y_train_orig[i,0]=np.asarray(train_data[i]['is_iceberg']).reshape(1,1)\n",
    "    X_train_orig_lin[i,:,:,0]=np.power(10,X_train_orig[i,:,:,0]/10)\n",
    "    X_train_orig_lin[i,:,:,1]=np.power(10,X_train_orig[i,:,:,1]/10)\n",
    "    if train_data[i]['inc_angle']!='na':\n",
    "        if np.asarray(train_data[i]['inc_angle'])<30:\n",
    "            mean=np.mean(X_train_orig_lin[i,:,:,1])\n",
    "            std_dev=np.std(X_train_orig_lin[i,:,:,1])\n",
    "            threshold=mean+0.8*std_dev\n",
    "            ind_mat=X_train_orig_lin[i,:,:,1]>threshold\n",
    "        else:\n",
    "            mean=np.mean(X_train_orig_lin[i,:,:,0])\n",
    "            std_dev=np.std(X_train_orig_lin[i,:,:,0])\n",
    "            threshold=mean+0.8*std_dev\n",
    "            ind_mat=X_train_orig_lin[i,:,:,0]>threshold\n",
    "    else:\n",
    "        mean=np.mean(X_train_orig_lin[i,:,:,0])\n",
    "        std_dev=np.std(X_train_orig_lin[i,:,:,0])\n",
    "        threshold=mean+0.8*std_dev\n",
    "        ind_mat=X_train_orig_lin[i,:,:,0]>threshold\n",
    "            \n",
    "    X_train_orig[i,:,:,0]=np.multiply(X_train_orig[i,:,:,0],ind_mat)\n",
    "    X_train_orig[i,:,:,1]=np.multiply(X_train_orig[i,:,:,1],ind_mat)\n",
    "            \n",
    "    #    if np.asarray(train_data[i]['inc_angle'])<30:\n",
    "    #        X_train_orig[i,:,:,0]=X_train_orig[i,:,:,0]*5\n",
    "    #    else:\n",
    "    #        X_train_orig[i,:,:,1]=X_train_orig[i,:,:,1]*5\n",
    "\n",
    "\n",
    "Y_train_orig=np.int_(Y_train_orig.reshape(1604,1))\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    X_test_orig[i,:,:,0]=np.asarray(test_data[i]['band_1']).reshape(IMG_SIZE,IMG_SIZE)\n",
    "    X_test_orig[i,:,:,1]=np.asarray(test_data[i]['band_2']).reshape(IMG_SIZE,IMG_SIZE)\n",

    "a=np.arange(X_train_orig.shape[0])\n",
    "\n",
    "np.random.shuffle(a)\n",
    "print(a.shape[0])\n",
    "train_ind=1400\n",
    "X_train=X_train_orig[a[0:train_ind]]\n",
    "Y_train=Y_train_orig[a[0:train_ind]]\n",
    "\n",
    "\n",
    "X_test=X_train_orig[a[train_ind:1604]]\n",
    "Y_test=Y_train_orig[a[train_ind:1604]]\n",
    "\n",
    "Y_train = convert_to_one_hot(Y_train, 2).T\n",
    "Y_test = convert_to_one_hot(Y_test, 2).T\n",
    "\n",
    "print(Y_train.shape,X_train.shape,X_test_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.4878\n",
      "[1]\n",
      "-0.4427015632 0.0182635708538\n",
      "[[-0. -0. -0. ..., -0. -0. -0.]\n",
      " [-0. -0. -0. ..., -0. -0. -0.]\n",
      " [-0. -0. -0. ..., -0. -0. -0.]\n",
      " ..., \n",
      " [-0. -0. -0. ..., -0. -0. -0.]\n",
      " [-0. -0. -0. ..., -0. -0. -0.]\n",
      " [-0. -0. -0. ..., -0. -0. -0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe9f5d1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id=530\n",
    "print(train_data[id]['inc_angle'])\n",
    "print(Y_train_orig[id])\n",
    "x1=X_train_orig[id,:,:,0]\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "print(np.mean(X_train_orig[id,:,:,0]),np.mean(X_train_orig_lin[id,:,:,0]))\n",
    "axarr[0].imshow(X_train_orig[id,:,:,0])\n",
    "axarr[1].imshow(X_train_orig[id,:,:,1])\n",
    "print(X_train_orig[id,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1099  | total loss: 0.35328 | time: 6.076s\n",
      "| Adam | epoch: 050 | loss: 0.35328 - acc: 0.8580 -- iter: 1344/1400\n",
      "Training Step: 1100  | total loss: 0.34434 | time: 7.361s\n",
      "| Adam | epoch: 050 | loss: 0.34434 - acc: 0.8613 | val_loss: 0.38006 - val_acc: 0.8284 -- iter: 1400/1400\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected, flatten, one_hot_encoding\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "\n",
    "# Create extra synthetic training data by flipping, rotating and blurring the\n",
    "# images on our data set.\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)\n",
    "img_aug.add_random_blur(sigma_max=3.)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 2], data_augmentation=img_aug, name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 3, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 3, padding ='valid')\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 3, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 3)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 3, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 3, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 3, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = flatten(convnet)\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.9)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=1e-3, loss='categorical_crossentropy',name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "model.fit({'input': X_train}, {'targets': Y_train}, n_epoch=50, validation_set=({'input': X_test}, {'targets': Y_test}), \n",
    "    snapshot_step=500, show_metric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = model.predict(X_test_orig)\n",
    "#prediction=np.empty([100,1])\n",
    "ind=3500\n",
    "prediction=model_out[:,1]\n",
    "\n",
    "print(model_out[ind],prediction[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
